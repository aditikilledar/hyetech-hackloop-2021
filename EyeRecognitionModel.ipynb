{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9PPHviVZk3U-",
    "outputId": "4b012fc3-8178-41b9-901f-e118afebf356",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gOVF5DeOeIdl",
    "outputId": "33f696fa-beab-4149-cc22-e32561681406",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zpQtN3SqqeoD"
   },
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AJ8Ac7wugy70"
   },
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# while(True):\n",
    "#     ret, img = cap.read()\n",
    "#     cv2.imshow(\"Output\", img)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Cttj6mp2qqyW"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('./face.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert to grayscale \n",
    "detector = dlib.get_frontal_face_detector()\n",
    "rects = detector(gray, 1) # rects contains all the faces detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hwLqLYylGRfj"
   },
   "outputs": [],
   "source": [
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    coords = np.zeros((68, 2), dtype=dtype)\n",
    "    for i in range(0, 68):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-EecOGbSGT_2"
   },
   "outputs": [],
   "source": [
    "predictor = dlib.shape_predictor(r'C:\\Users\\d3583\\OneDrive\\Documents\\PESU\\hyetech-hackloop-2021\\facial-landmarks-recognition-master\\shape_predictor_68_face_landmarks.dat')\n",
    "for (i, rect) in enumerate(rects):\n",
    "    shape = predictor(gray, rect)\n",
    "    shape = shape_to_np(shape)\n",
    "    for (x, y) in shape:\n",
    "        cv2.circle(img, (x, y), 2, (0, 0, 255), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bxc8G24Ldol8"
   },
   "outputs": [],
   "source": [
    "def eye_on_mask(mask, side):\n",
    "    points = [shape[i] for i in side]\n",
    "    points = np.array(points, dtype=np.int32)\n",
    "    mask = cv2.fillConvexPoly(mask, points, 255)\n",
    "    return mask\n",
    "left = [36, 37, 38, 39, 40, 41] # keypoint indices for left eye\n",
    "right = [42, 43, 44, 45, 46, 47] # keypoint indices for right eye\n",
    "mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "mask = eye_on_mask(mask, left)\n",
    "mask = eye_on_mask(mask, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QStlpYnzpPOQ"
   },
   "outputs": [],
   "source": [
    "kernel = np.ones((9, 9), np.uint8)\n",
    "mask = cv2.dilate(mask, kernel, 5)\n",
    "eyes = cv2.bitwise_and(img, img, mask=mask)\n",
    "mask = (eyes == [0, 0, 0]).all(axis=2)\n",
    "eyes[mask] = [255, 255, 255]\n",
    "eyes_gray = cv2.cvtColor(eyes, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MWus_PDBpVkv"
   },
   "outputs": [],
   "source": [
    "def nothing(x):\n",
    "    pass\n",
    "cv2.namedWindow('image')\n",
    "cv2.createTrackbar('threshold', 'image', 0, 255, nothing)\n",
    "threshold = cv2.getTrackbarPos('threshold', 'image')\n",
    "_, thresh = cv2.threshold(eyes_gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "thresh = cv2.erode(thresh, None, iterations=2)\n",
    "thresh = cv2.dilate(thresh, None, iterations=4)\n",
    "thresh = cv2.medianBlur(thresh, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contouring(thresh, mid, img, right=False):\n",
    "    cnts, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    cnt = max(cnts, key = cv2.contourArea) # finding contour with #maximum area\n",
    "    M = cv2.moments(cnt)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    if right:\n",
    "        cx += mid # Adding value of mid to x coordinate of centre of #right eye to adjust for dividing into two parts\n",
    "    cv2.circle(img, (cx, cy), 4, (0, 0, 255), 2)# drawing over #eyeball with red\n",
    "mid = (shape[39][0] + shape[42][0]) // 2\n",
    "contouring(thresh[:, 0:mid], mid, img)\n",
    "contouring(thresh[:, mid:], mid, img, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contouring(thresh, mid, img, right=False):\n",
    "    cnts, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    try:\n",
    "        cnt = max(cnts, key = cv2.contourArea)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        if right:\n",
    "            cx += mid\n",
    "        cv2.circle(img, (cx, cy), 4, (0, 0, 255), 2)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EyeRecognitionModel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "envname",
   "language": "python",
   "name": "envname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
