# Hackloop-2021: HYE TECH
A repository of our team's work from Hackloop 2021, a 27-hour hackathon.
Dataset - https://www.kaggle.com/kayvanshah/eye-dataset
Problem statement:
Wheelchair-using individuals may have trouble controlling the movements of the wheelchair-- due to existing health conditions, and may need help navigating. Most wheelchairs today require external assistance for a person to move around or are remote-controlled. It can be difficult finding this assistance for most.

Our solution:

Our solution aims to enable their independence. We propose an automated wheelchair that moves by recognizing the direction of the eye's gaze of the person seated on it, activated by a button on the wheelchair itself, along with proximity sensors for safety. A camera captures the eyes, sends signals to the system, which in turn moves the wheelchair in that direction. 
We will implement this as a prototype in the hackathon, through an app that reads camera input and based on the input images it receives, it predicts the direction in which the person's eye is looking. 
